{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbI2H6bGNbXU"
      },
      "source": [
        "CNNs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "_82o2yfSoAw7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VxhvGzxNZSk",
        "outputId": "f0b6a05d-5c71-4ca0-ee87-b7d0ee6c63e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (2.8.0)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.2.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.0.1+cu118)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.9.0)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (23.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.12.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (17.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
            "Collecting torcheval\n",
            "  Downloading torcheval-0.0.7-py3-none-any.whl (179 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.2/179.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torcheval) (4.5.0)\n",
            "Installing collected packages: torcheval\n",
            "Successfully installed torcheval-0.0.7\n",
            "Collecting ray\n",
            "  Downloading ray-2.7.1-cp310-cp310-manylinux2014_x86_64.whl (62.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray) (3.12.4)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray) (4.19.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray) (1.0.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray) (23.2)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray) (6.0.1)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray) (1.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray) (2.31.0)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from ray) (1.23.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (0.10.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (2023.7.22)\n",
            "Installing collected packages: ray\n",
            "Successfully installed ray-2.7.1\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.2.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.0.1+cu118)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.9.0)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (23.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.12.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (17.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import io\n",
        "import requests\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import spacy\n",
        "!pip install emoji\n",
        "from emoji import demojize\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "!pip install torchmetrics\n",
        "!pip install torcheval\n",
        "from torchmetrics.classification import MulticlassF1Score\n",
        "from torcheval.metrics.functional import multiclass_f1_score\n",
        "import torch.optim as optim\n",
        "from torch import autograd\n",
        "import random\n",
        "!pip install ray\n",
        "!pip install torchmetrics\n",
        "from ray import tune\n",
        "from ray.tune import CLIReporter\n",
        "import string\n",
        "exclude = string.punctuation\n",
        "\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stopwords_english = stopwords.words('english')\n",
        "\n",
        "from nltk import word_tokenize, pos_tag\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6QW7N7rN6pN"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.blank(\"en\")\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6l_Ryvs5OMV1",
        "outputId": "10206c1b-c318-4fac-ea42-5adbf9f7d412"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device name: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "# use the GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwP3_izQ30Wa"
      },
      "source": [
        "Importing and converting data into dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzhaqbTjON5S",
        "outputId": "b4ac3e27-5088-4577-b944-41c0528a5133"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'tweeteval'...\n",
            "remote: Enumerating objects: 370, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 370 (delta 13), reused 3 (delta 1), pack-reused 354\u001b[K\n",
            "Receiving objects: 100% (370/370), 8.49 MiB | 15.99 MiB/s, done.\n",
            "Resolving deltas: 100% (122/122), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/cardiffnlp/tweeteval.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RWwjPkZcJ4M"
      },
      "outputs": [],
      "source": [
        "def load_text(path):\n",
        "\n",
        "    with open(path, 'rb') as f:\n",
        "        texts = []\n",
        "        for line in f:\n",
        "            texts.append(line.decode(errors='ignore').lower().strip())\n",
        "\n",
        "    return texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQ6lYXh0PWDG"
      },
      "outputs": [],
      "source": [
        "train_text = load_text(\"/content/tweeteval/datasets/emotion/train_text.txt\")\n",
        "train_labels = load_text(\"/content/tweeteval/datasets/emotion/train_labels.txt\")\n",
        "test_text = load_text(\"/content/tweeteval/datasets/emotion/test_text.txt\")\n",
        "test_labels = load_text(\"/content/tweeteval/datasets/emotion/test_labels.txt\")\n",
        "val_text = load_text(\"/content/tweeteval/datasets/emotion/val_text.txt\")\n",
        "val_labels = load_text(\"/content/tweeteval/datasets/emotion/val_labels.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IE6zMBiNcoWo"
      },
      "outputs": [],
      "source": [
        "train_data = list(zip(train_text,train_labels))\n",
        "test_data = list(zip(test_text,test_labels))\n",
        "val_data = list(zip(val_text,val_labels))\n",
        "\n",
        "df_train = pd.DataFrame(train_data,columns=[\"tweet\",\"label\"])\n",
        "df_test = pd.DataFrame(test_data,columns=[\"tweet\",\"label\"])\n",
        "df_val = pd.DataFrame(val_data,columns=[\"tweet\",\"label\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNWaLAgjpBy0",
        "outputId": "4f5d3ba9-2be2-404c-ff57-b459b48277b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3257 entries, 0 to 3256\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   tweet   3257 non-null   object\n",
            " 1   label   3257 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 51.0+ KB\n"
          ]
        }
      ],
      "source": [
        "df_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVgKdyElifZ0",
        "outputId": "fccab8c0-96e6-41da-894d-809281ec4d22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1400 tweets labeled 0\n",
            "There are 708 tweets labeled 1\n",
            "There are 294 tweets labeled 2\n",
            "There are 855 tweets labeled 3\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print('There are {} tweets labeled 0'.format(len(df_train[df_train[\"label\"].isin(['0'])])))\n",
        "print('There are {} tweets labeled 1'.format(len(df_train[df_train[\"label\"].isin(['1'])])))\n",
        "print('There are {} tweets labeled 2'.format(len(df_train[df_train[\"label\"].isin(['2'])])))\n",
        "print('There are {} tweets labeled 3'.format(len(df_train[df_train[\"label\"].isin(['3'])])))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting the frequency distribution of the tweet emotion\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.hist(df_train[\"label\"])\n",
        "plt.xlabel(\"Label\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Distribution of the Tweet Emotion in train data\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "nRf3tAjt5uv6",
        "outputId": "3aa7c677-24f0-4cd0-8bc6-16d69395a03b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9kj0yfy4LsE"
      },
      "source": [
        "Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIZgisPBl9bg"
      },
      "outputs": [],
      "source": [
        "# data preprocessing class\n",
        "class Preprocessing:\n",
        "\n",
        "  # lowercasing\n",
        "  def convert_lowercase(self,text):\n",
        "      text = text.lower()\n",
        "      return text\n",
        "\n",
        "  # removing html tags\n",
        "  def remove_html_tags(self,text):\n",
        "      re_html = re.compile('<.*?>')\n",
        "      return re_html.sub(r'', text)\n",
        "\n",
        "  # removing URLS\n",
        "  def remove_url(self,text):\n",
        "      re_url = re.compile('https?://\\S+|www\\.\\S+')\n",
        "      return re_url.sub('', text)\n",
        "\n",
        "  # removing punctuations\n",
        "  def remove_punc(self,text):\n",
        "      return text.translate(str.maketrans('', '', exclude))\n",
        "\n",
        "  # removing special characters\n",
        "  def remove_special(self,text):\n",
        "      x=''\n",
        "      for i in text:\n",
        "          if i.isalnum():\n",
        "              x=x+i\n",
        "          else:\n",
        "              x=x+' '\n",
        "      return x\n",
        "\n",
        "  # removing digits\n",
        "  def remove_digits(self,text):\n",
        "      filtered_string = ''.join((x for x in text if not x.isdigit()))\n",
        "      return filtered_string\n",
        "\n",
        "  def demojize(self,text):\n",
        "      return demojize(text)\n",
        "\n",
        "  # removing stop words\n",
        "  def remove_stopwords(self,text):\n",
        "      new_text = []\n",
        "      for word in text.split():\n",
        "          if word in stopwords_english:\n",
        "              continue\n",
        "          else:\n",
        "              new_text.append(word)\n",
        "\n",
        "      return ' '.join(new_text)\n",
        "\n",
        "  def preprocess(self,text):\n",
        "    full_text = []\n",
        "    for sent in text:\n",
        "      sent = self.convert_lowercase(sent)\n",
        "      sent = self.remove_html_tags(sent)\n",
        "      sent = self.remove_url(sent)\n",
        "      sent = self.remove_digits(sent)\n",
        "      sent = self.remove_punc(sent)\n",
        "      sent = self.remove_special(sent)\n",
        "      sent = self.remove_stopwords(sent)\n",
        "      sent = self.demojize(sent)\n",
        "      full_text.append(sent)\n",
        "    return full_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zA4vN20R4VNp"
      },
      "source": [
        "Data tokentization and encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMuYmiRxihN1"
      },
      "outputs": [],
      "source": [
        "# function for text tokentization\n",
        "\n",
        "def tokenize(texts):\n",
        "  max_len = 0\n",
        "  tokenized_texts = []\n",
        "  word2idx = {}\n",
        "\n",
        "  # Add <pad> and <unk> tokens to the vocabulary\n",
        "  word2idx['<pad>'] = 0\n",
        "  word2idx['<unk>'] = 1\n",
        "\n",
        "  # Building our vocab from the corpus starting from index 2\n",
        "  idx = 2\n",
        "  for sent in texts:\n",
        "    tokenized_sent = nlp(sent)\n",
        "    # Add `tokenized_sent` to `tokenized_texts`\n",
        "    tokenized_texts.append(tokenized_sent)\n",
        "    # Add new token to `word2idx`\n",
        "    for token in tokenized_sent:\n",
        "      # string any token objects are different things, be careful.\n",
        "      if token.text not in word2idx:\n",
        "        word2idx[token.text] = idx\n",
        "        idx += 1\n",
        "\n",
        "        # Update `max_len`\n",
        "    max_len = max(max_len, len(tokenized_sent))\n",
        "\n",
        "  return tokenized_texts, word2idx, max_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KffQHlJzl3E-"
      },
      "outputs": [],
      "source": [
        "# function for converting words into numeric ids\n",
        "def encode(tokenized_texts, word2idx, max_len):\n",
        "    input_ids = []\n",
        "    for tokenized_sent in tokenized_texts:\n",
        "        # Pad sentences to max_len\n",
        "        tokenized_padded_sent = list(tokenized_sent) + ['<pad>'] * (max_len - len(tokenized_sent))\n",
        "\n",
        "        # Encode tokens to input_ids, assign value 1 if word doesn't exist in vocabulary\n",
        "        input_id = [word2idx.get(str(token)) if str(token) in word2idx else 1 for token in tokenized_padded_sent]\n",
        "        input_ids.append(input_id)\n",
        "\n",
        "    return np.array(input_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0EZ7Clv4bXC"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kb-yynf9oJqf"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self,\n",
        "                 vocab_size,\n",
        "                 embed_dim=300,\n",
        "                 filter_sizes=[3, 4, 5],\n",
        "                 num_filters=[100, 100, 100],\n",
        "                 num_classes=4,\n",
        "                 dropout=0.5):\n",
        "\n",
        "        super(CNN, self).__init__()\n",
        "        # Random Embedding layer\n",
        "        self.embed_dim = embed_dim\n",
        "        self.embedding = nn.Embedding(num_embeddings=vocab_size,\n",
        "                                          embedding_dim=self.embed_dim,\n",
        "                                          padding_idx=0,\n",
        "                                          max_norm=5.0)\n",
        "        # Conv Network\n",
        "        self.conv1d_list = nn.ModuleList([\n",
        "            nn.Conv1d(in_channels=self.embed_dim,\n",
        "                      out_channels=num_filters[i],\n",
        "                      kernel_size=filter_sizes[i])\n",
        "            for i in range(len(filter_sizes))\n",
        "        ])\n",
        "        # Fully-connected layer and Dropout\n",
        "        self.fc = nn.Linear(np.sum(num_filters), 4)\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "\n",
        "        # Get embeddings from `input_ids`. Output shape: (b, max_len, embed_dim)\n",
        "        x_embed = self.embedding(input_ids).float()\n",
        "\n",
        "        # Permute `x_embed` to match input shape requirement of `nn.Conv1d`.\n",
        "        # Output shape: (b, embed_dim, max_len)\n",
        "        x_reshaped = x_embed.permute(0, 2, 1)\n",
        "\n",
        "        # Apply CNN and ReLU. Output shape: (b, num_filters[i], L_out)\n",
        "        x_conv_list = [F.relu(conv1d(x_reshaped)) for conv1d in self.conv1d_list]\n",
        "\n",
        "        # Max pooling. Output shape: (b, num_filters[i], 1)\n",
        "        x_pool_list = [F.max_pool1d(x_conv, kernel_size=x_conv.shape[2])\n",
        "            for x_conv in x_conv_list]\n",
        "\n",
        "        # Concatenate x_pool_list to feed the fully connected layer.\n",
        "        # Output shape: (b, sum(num_filters))\n",
        "        x_fc = torch.cat([x_pool.squeeze(dim=2) for x_pool in x_pool_list],\n",
        "                         dim=1)\n",
        "\n",
        "        # Compute logits. Output shape: (b, n_classes)\n",
        "        logits = self.fc(self.dropout(x_fc))\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnRZQ4SU1ETs"
      },
      "outputs": [],
      "source": [
        "# Our model class have preprocessing, encoding, data loader and train_model functions\n",
        "class model_emotions:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  # Takes training data and returns the processed tensor of input data and its labels\n",
        "  # Also returns the word2idx dictionary for validation and test data preprocessing\n",
        "  def get_train_tokenizors(self,train_data):\n",
        "    self.train_data = train_data\n",
        "    preprocessed_text_train = Preprocessing().preprocess(self.train_data[\"tweet\"])\n",
        "    tokenized_texts, word2idx, max_len = tokenize(preprocessed_text_train)\n",
        "    input_ids_train = encode(tokenized_texts, word2idx, max_len)\n",
        "\n",
        "    # train label encoders\n",
        "    label_encoder = LabelEncoder()\n",
        "    train_data_labels = label_encoder.fit_transform(self.train_data[\"label\"])\n",
        "\n",
        "\n",
        "    #convert train inputs and labels to torch tensor\n",
        "\n",
        "    train_inputs = torch.from_numpy(input_ids_train)\n",
        "    labels_train = torch.from_numpy(train_data_labels)\n",
        "\n",
        "    return word2idx, max_len, train_inputs, labels_train\n",
        "\n",
        "  # returns the validation or test tensors\n",
        "  def get_processed_data(self,data,word2idx,max_len):\n",
        "    # preprocess the training and the validation data- learn the vocabulary from the training data and only encode the validation data\n",
        "    preprocessed_text = Preprocessing().preprocess(data[\"tweet\"])\n",
        "    input_ids = encode([nlp(sent) for sent in preprocessed_text], word2idx, max_len)\n",
        "\n",
        "    # label encoders\n",
        "\n",
        "    label_encoder = LabelEncoder()\n",
        "    data_labels = label_encoder.fit_transform(data[\"label\"])\n",
        "\n",
        "    # Convert data type to torch.Tensor for input_ids and data_labels\n",
        "\n",
        "    inputs = torch.from_numpy(input_ids)\n",
        "    labels_data = torch.from_numpy(data_labels)\n",
        "\n",
        "    return inputs, labels_data\n",
        "\n",
        "  # takes the tensors and returns the DataLoader of training data\n",
        "  def get_dataloader(self,train_data_tensor,labels_train_tensor,batch_size):\n",
        "\n",
        "    # Specify batch_size\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "    # Create DataLoader for training data\n",
        "    train_data = TensorDataset(train_data_tensor, labels_train_tensor)\n",
        "    train_sampler = RandomSampler(train_data)\n",
        "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "    return train_dataloader\n",
        "\n",
        "  # train the model\n",
        "  def train_model(self,config):\n",
        "\n",
        "    train_data = config[\"train_data\"]\n",
        "    val_data = config[\"val_data\"]\n",
        "\n",
        "\n",
        "    # get the tensorial forms of the train and validation data\n",
        "    word2idx,max_len,inputs_train,labels_train = self.get_train_tokenizors(train_data)\n",
        "    inputs_val, labels_val = self.get_processed_data(val_data,word2idx,max_len)\n",
        "\n",
        "    batch_size = config[\"batch_size\"]\n",
        "\n",
        "\n",
        "    model = CNN(vocab_size = len(word2idx),\n",
        "                 embed_dim = 300,\n",
        "                 filter_sizes = config[\"filter_sizes\"],\n",
        "                 num_filters = config[\"num_filters\"],\n",
        "                 num_classes = 4,\n",
        "                 dropout = config[\"dropout\"])\n",
        "\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    # testing Adam and Adadelta optimizers\n",
        "\n",
        "    # optimizer = optim.Adadelta(model.parameters(),\n",
        "    #                            lr = config[\"lr\"],\n",
        "    #                            rho = 0.95)\n",
        "\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(),\n",
        "                              lr = config[\"lr\"])\n",
        "\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    # get the dataloader\n",
        "    train_dataloader = self.get_dataloader(inputs_train,labels_train,batch_size)\n",
        "\n",
        "    train_loss_per_epoch = []\n",
        "    val_loss_per_epoch = []\n",
        "\n",
        "    epochs = 10\n",
        "    mean_val_acc = 0\n",
        "\n",
        "    # train the model on the training data\n",
        "    for epoch_i in range(epochs):\n",
        "      total_loss = 0\n",
        "      # Put the model into the training mode\n",
        "      model.train()\n",
        "      for step, batch in enumerate(train_dataloader):\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_labels = tuple(t.to(device) for t in batch)\n",
        "        b_labels = b_labels.type(torch.LongTensor)\n",
        "        b_input_ids = b_input_ids.to(device)\n",
        "        b_labels = b_labels.to(device)\n",
        "        # Zero out any previously calculated gradients\n",
        "        model.zero_grad()\n",
        "        # Perform a forward pass. This will return logits.\n",
        "        logits = model(b_input_ids)\n",
        "        # Compute loss and accumulate the loss values\n",
        "        loss = loss_fn(logits, b_labels)\n",
        "        total_loss += loss.item()\n",
        "        # Perform a backward pass to calculate gradients\n",
        "        loss.backward()\n",
        "        # Update parameters\n",
        "        optimizer.step()\n",
        "\n",
        "      # Calculate the average loss over the entire training data\n",
        "      avg_train_loss = total_loss / len(train_dataloader)\n",
        "      train_loss_per_epoch.append(avg_train_loss)\n",
        "\n",
        "      # test the model on the validation data\n",
        "      model.eval()\n",
        "      val_data, val_labels = inputs_val.to(device), labels_val.type(torch.LongTensor).to(device)\n",
        "      val_labels_pred = model(val_data)\n",
        "      val_loss = loss_fn(val_labels_pred,val_labels)\n",
        "      val_loss = val_loss.item()\n",
        "      val_loss_per_epoch.append(val_loss)\n",
        "\n",
        "      # validation accuracy\n",
        "      val_accuracy = (torch.argmax(val_labels_pred, dim = 1) == val_labels).sum().item() / len(val_labels)\n",
        "      mean_val_acc += val_accuracy / epochs\n",
        "\n",
        "      #f1 score on validation data\n",
        "      f1_score_val = multiclass_f1_score(val_labels_pred, val_labels, average=\"macro\",num_classes=4).to(device)\n",
        "\n",
        "    # adding this to configuration as ray doesn't work if function returns values\n",
        "    # we only need validation loss and accuracy for hyperparameter tuning\n",
        "    if config[\"train\"]==True:\n",
        "      train.report({'loss': val_loss, 'accuracy': mean_val_acc, 'f1_score': f1_score_val.item()})\n",
        "  #this will send validation loss and accuracy to Tune\n",
        "    else:\n",
        "\n",
        "      return word2idx, max_len, model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EpRZjPCOl8i",
        "outputId": "47589f1f-afba-4377-9d61-10e1dd4fe30e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-10-17 19:42:25,813\tINFO tune.py:654 -- [output] This will use the new output engine with verbosity 2. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
            "2023-10-17 19:42:25,819\tINFO registry.py:107 -- Detected unknown callable for trainable. Converting to class.\n",
            "2023-10-17 19:42:25,861\tWARNING callback.py:137 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n",
            "2023-10-17 19:42:25,863\tWARNING tune.py:997 -- AIR_VERBOSITY is set, ignoring passed-in ProgressReporter for now.\n",
            "2023-10-17 19:42:25,869\tINFO experiment_state.py:524 -- No local checkpoint was found. Ray Tune will now start a new experiment.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------------------+\n",
            "| Configuration for experiment     train_model_2023-10-17_19-42-25   |\n",
            "+--------------------------------------------------------------------+\n",
            "| Search algorithm                 BasicVariantGenerator             |\n",
            "| Scheduler                        FIFOScheduler                     |\n",
            "| Number of trials                 18                                |\n",
            "+--------------------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /root/ray_results/train_model_2023-10-17_19-42-25\n",
            "\n",
            "Trial status: 16 PENDING\n",
            "Current time: 2023-10-17 19:42:31. Total running time: 5s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:None)\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Trial name                status       dropout     batch_size   num_filters          lr |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| train_model_4c6ec_00000   PENDING          0.6              8   [100, 100, 100]   0.1   |\n",
            "| train_model_4c6ec_00001   PENDING          0.6             16   [100, 100, 100]   0.1   |\n",
            "| train_model_4c6ec_00002   PENDING          0.5             24   [100, 100, 100]   0.1   |\n",
            "| train_model_4c6ec_00003   PENDING          0.8              8   [100, 100, 100]   0.001 |\n",
            "| train_model_4c6ec_00004   PENDING          0.6             16   [100, 100, 100]   0.001 |\n",
            "| train_model_4c6ec_00005   PENDING          0.5             24   [100, 100, 100]   0.001 |\n",
            "| train_model_4c6ec_00006   PENDING          0.5              8   [100, 100, 100]   0.01  |\n",
            "| train_model_4c6ec_00007   PENDING          0.5             16   [100, 100, 100]   0.01  |\n",
            "| train_model_4c6ec_00008   PENDING          0.6             24   [100, 100, 100]   0.01  |\n",
            "| train_model_4c6ec_00009   PENDING          0.8              8   [150, 150, 150]   0.1   |\n",
            "| train_model_4c6ec_00010   PENDING          0.6             16   [150, 150, 150]   0.1   |\n",
            "| train_model_4c6ec_00011   PENDING          0.5             24   [150, 150, 150]   0.1   |\n",
            "| train_model_4c6ec_00012   PENDING          0.8              8   [150, 150, 150]   0.001 |\n",
            "| train_model_4c6ec_00013   PENDING          0.6             16   [150, 150, 150]   0.001 |\n",
            "| train_model_4c6ec_00014   PENDING          0.6             24   [150, 150, 150]   0.001 |\n",
            "| train_model_4c6ec_00015   PENDING          0.8              8   [150, 150, 150]   0.01  |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=2755)\u001b[0m 2023-10-17 19:42:38.452609: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial train_model_4c6ec_00000 started with configuration:\n",
            "+---------------------------------------------------------------+\n",
            "| Trial train_model_4c6ec_00000 config                          |\n",
            "+---------------------------------------------------------------+\n",
            "| batch_size                                                  8 |\n",
            "| dropout                                                   0.6 |\n",
            "| filter_sizes                                        [3, 4, 5] |\n",
            "| lr                                                        0.1 |\n",
            "| num_filters                                   [100, 100, 100] |\n",
            "| train                                                    True |\n",
            "| train_data                               ...rows x 2 columns] |\n",
            "| val_data                                 ...rows x 2 columns] |\n",
            "+---------------------------------------------------------------+\n",
            "\n",
            "Trial train_model_4c6ec_00000 finished iteration 1 at 2023-10-17 19:42:57. Total running time: 31s\n",
            "+--------------------------------------------------+\n",
            "| Trial train_model_4c6ec_00000 result             |\n",
            "+--------------------------------------------------+\n",
            "| checkpoint_dir_name                              |\n",
            "| time_this_iter_s                         16.8675 |\n",
            "| time_total_s                             16.8675 |\n",
            "| training_iteration                             1 |\n",
            "| accuracy                                 0.45027 |\n",
            "| f1_score                                 0.37184 |\n",
            "| loss                                     692.174 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial train_model_4c6ec_00000 completed after 1 iterations at 2023-10-17 19:42:57. Total running time: 31s\n",
            "\n",
            "Trial status: 1 TERMINATED | 16 PENDING\n",
            "Current time: 2023-10-17 19:43:01. Total running time: 35s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:None)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         dropout     batch_size   num_filters          lr     iter     total time (s)      loss     accuracy     f1_score |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_model_4c6ec_00000   TERMINATED         0.6              8   [100, 100, 100]   0.1          1            16.8675   692.174     0.450267     0.371838 |\n",
            "| train_model_4c6ec_00001   PENDING            0.6             16   [100, 100, 100]   0.1                                                                   |\n",
            "| train_model_4c6ec_00002   PENDING            0.5             24   [100, 100, 100]   0.1                                                                   |\n",
            "| train_model_4c6ec_00003   PENDING            0.8              8   [100, 100, 100]   0.001                                                                 |\n",
            "| train_model_4c6ec_00004   PENDING            0.6             16   [100, 100, 100]   0.001                                                                 |\n",
            "| train_model_4c6ec_00005   PENDING            0.5             24   [100, 100, 100]   0.001                                                                 |\n",
            "| train_model_4c6ec_00006   PENDING            0.5              8   [100, 100, 100]   0.01                                                                  |\n",
            "| train_model_4c6ec_00007   PENDING            0.5             16   [100, 100, 100]   0.01                                                                  |\n",
            "| train_model_4c6ec_00008   PENDING            0.6             24   [100, 100, 100]   0.01                                                                  |\n",
            "| train_model_4c6ec_00009   PENDING            0.8              8   [150, 150, 150]   0.1                                                                   |\n",
            "| train_model_4c6ec_00010   PENDING            0.6             16   [150, 150, 150]   0.1                                                                   |\n",
            "| train_model_4c6ec_00011   PENDING            0.5             24   [150, 150, 150]   0.1                                                                   |\n",
            "| train_model_4c6ec_00012   PENDING            0.8              8   [150, 150, 150]   0.001                                                                 |\n",
            "| train_model_4c6ec_00013   PENDING            0.6             16   [150, 150, 150]   0.001                                                                 |\n",
            "| train_model_4c6ec_00014   PENDING            0.6             24   [150, 150, 150]   0.001                                                                 |\n",
            "| train_model_4c6ec_00015   PENDING            0.8              8   [150, 150, 150]   0.01                                                                  |\n",
            "| train_model_4c6ec_00016   PENDING            0.5             16   [150, 150, 150]   0.01                                                                  |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=2927)\u001b[0m 2023-10-17 19:43:04.111183: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial train_model_4c6ec_00001 started with configuration:\n",
            "+---------------------------------------------------------------+\n",
            "| Trial train_model_4c6ec_00001 config                          |\n",
            "+---------------------------------------------------------------+\n",
            "| batch_size                                                 16 |\n",
            "| dropout                                                   0.6 |\n",
            "| filter_sizes                                        [3, 4, 5] |\n",
            "| lr                                                        0.1 |\n",
            "| num_filters                                   [100, 100, 100] |\n",
            "| train                                                    True |\n",
            "| train_data                               ...rows x 2 columns] |\n",
            "| val_data                                 ...rows x 2 columns] |\n",
            "+---------------------------------------------------------------+\n",
            "\n",
            "Trial train_model_4c6ec_00001 finished iteration 1 at 2023-10-17 19:43:18. Total running time: 52s\n",
            "+--------------------------------------------------+\n",
            "| Trial train_model_4c6ec_00001 result             |\n",
            "+--------------------------------------------------+\n",
            "| checkpoint_dir_name                              |\n",
            "| time_this_iter_s                         10.8714 |\n",
            "| time_total_s                             10.8714 |\n",
            "| training_iteration                             1 |\n",
            "| accuracy                                 0.47112 |\n",
            "| f1_score                                   0.435 |\n",
            "| loss                                     408.001 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial train_model_4c6ec_00001 completed after 1 iterations at 2023-10-17 19:43:18. Total running time: 52s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=3082)\u001b[0m 2023-10-17 19:43:29.450397: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial status: 2 TERMINATED | 16 PENDING\n",
            "Current time: 2023-10-17 19:43:31. Total running time: 1min 5s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:None)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         dropout     batch_size   num_filters          lr     iter     total time (s)      loss     accuracy     f1_score |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_model_4c6ec_00000   TERMINATED         0.6              8   [100, 100, 100]   0.1          1            16.8675   692.174     0.450267     0.371838 |\n",
            "| train_model_4c6ec_00001   TERMINATED         0.6             16   [100, 100, 100]   0.1          1            10.8714   408.001     0.471123     0.435003 |\n",
            "| train_model_4c6ec_00002   PENDING            0.5             24   [100, 100, 100]   0.1                                                                   |\n",
            "| train_model_4c6ec_00003   PENDING            0.8              8   [100, 100, 100]   0.001                                                                 |\n",
            "| train_model_4c6ec_00004   PENDING            0.6             16   [100, 100, 100]   0.001                                                                 |\n",
            "| train_model_4c6ec_00005   PENDING            0.5             24   [100, 100, 100]   0.001                                                                 |\n",
            "| train_model_4c6ec_00006   PENDING            0.5              8   [100, 100, 100]   0.01                                                                  |\n",
            "| train_model_4c6ec_00007   PENDING            0.5             16   [100, 100, 100]   0.01                                                                  |\n",
            "| train_model_4c6ec_00008   PENDING            0.6             24   [100, 100, 100]   0.01                                                                  |\n",
            "| train_model_4c6ec_00009   PENDING            0.8              8   [150, 150, 150]   0.1                                                                   |\n",
            "| train_model_4c6ec_00010   PENDING            0.6             16   [150, 150, 150]   0.1                                                                   |\n",
            "| train_model_4c6ec_00011   PENDING            0.5             24   [150, 150, 150]   0.1                                                                   |\n",
            "| train_model_4c6ec_00012   PENDING            0.8              8   [150, 150, 150]   0.001                                                                 |\n",
            "| train_model_4c6ec_00013   PENDING            0.6             16   [150, 150, 150]   0.001                                                                 |\n",
            "| train_model_4c6ec_00014   PENDING            0.6             24   [150, 150, 150]   0.001                                                                 |\n",
            "| train_model_4c6ec_00015   PENDING            0.8              8   [150, 150, 150]   0.01                                                                  |\n",
            "| train_model_4c6ec_00016   PENDING            0.5             16   [150, 150, 150]   0.01                                                                  |\n",
            "| train_model_4c6ec_00017   PENDING            0.6             24   [150, 150, 150]   0.01                                                                  |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_model_4c6ec_00002 started with configuration:\n",
            "+---------------------------------------------------------------+\n",
            "| Trial train_model_4c6ec_00002 config                          |\n",
            "+---------------------------------------------------------------+\n",
            "| batch_size                                                 24 |\n",
            "| dropout                                                   0.5 |\n",
            "| filter_sizes                                        [3, 4, 5] |\n",
            "| lr                                                        0.1 |\n",
            "| num_filters                                   [100, 100, 100] |\n",
            "| train                                                    True |\n",
            "| train_data                               ...rows x 2 columns] |\n",
            "| val_data                                 ...rows x 2 columns] |\n",
            "+---------------------------------------------------------------+\n",
            "\n",
            "Trial train_model_4c6ec_00002 finished iteration 1 at 2023-10-17 19:43:38. Total running time: 1min 12s\n",
            "+--------------------------------------------------+\n",
            "| Trial train_model_4c6ec_00002 result             |\n",
            "+--------------------------------------------------+\n",
            "| checkpoint_dir_name                              |\n",
            "| time_this_iter_s                         6.95201 |\n",
            "| time_total_s                             6.95201 |\n",
            "| training_iteration                             1 |\n",
            "| accuracy                                 0.45775 |\n",
            "| f1_score                                 0.35421 |\n",
            "| loss                                     253.299 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial train_model_4c6ec_00002 completed after 1 iterations at 2023-10-17 19:43:38. Total running time: 1min 12s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=3226)\u001b[0m 2023-10-17 19:43:47.140542: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial train_model_4c6ec_00003 started with configuration:\n",
            "+---------------------------------------------------------------+\n",
            "| Trial train_model_4c6ec_00003 config                          |\n",
            "+---------------------------------------------------------------+\n",
            "| batch_size                                                  8 |\n",
            "| dropout                                                   0.8 |\n",
            "| filter_sizes                                        [3, 4, 5] |\n",
            "| lr                                                      0.001 |\n",
            "| num_filters                                   [100, 100, 100] |\n",
            "| train                                                    True |\n",
            "| train_data                               ...rows x 2 columns] |\n",
            "| val_data                                 ...rows x 2 columns] |\n",
            "+---------------------------------------------------------------+\n",
            "\n",
            "Trial status: 3 TERMINATED | 1 RUNNING | 14 PENDING\n",
            "Current time: 2023-10-17 19:44:01. Total running time: 1min 35s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:None)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         dropout     batch_size   num_filters          lr     iter     total time (s)      loss     accuracy     f1_score |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_model_4c6ec_00003   RUNNING            0.8              8   [100, 100, 100]   0.001                                                                 |\n",
            "| train_model_4c6ec_00000   TERMINATED         0.6              8   [100, 100, 100]   0.1          1           16.8675    692.174     0.450267     0.371838 |\n",
            "| train_model_4c6ec_00001   TERMINATED         0.6             16   [100, 100, 100]   0.1          1           10.8714    408.001     0.471123     0.435003 |\n",
            "| train_model_4c6ec_00002   TERMINATED         0.5             24   [100, 100, 100]   0.1          1            6.95201   253.299     0.457754     0.354213 |\n",
            "| train_model_4c6ec_00004   PENDING            0.6             16   [100, 100, 100]   0.001                                                                 |\n",
            "| train_model_4c6ec_00005   PENDING            0.5             24   [100, 100, 100]   0.001                                                                 |\n",
            "| train_model_4c6ec_00006   PENDING            0.5              8   [100, 100, 100]   0.01                                                                  |\n",
            "| train_model_4c6ec_00007   PENDING            0.5             16   [100, 100, 100]   0.01                                                                  |\n",
            "| train_model_4c6ec_00008   PENDING            0.6             24   [100, 100, 100]   0.01                                                                  |\n",
            "| train_model_4c6ec_00009   PENDING            0.8              8   [150, 150, 150]   0.1                                                                   |\n",
            "| train_model_4c6ec_00010   PENDING            0.6             16   [150, 150, 150]   0.1                                                                   |\n",
            "| train_model_4c6ec_00011   PENDING            0.5             24   [150, 150, 150]   0.1                                                                   |\n",
            "| train_model_4c6ec_00012   PENDING            0.8              8   [150, 150, 150]   0.001                                                                 |\n",
            "| train_model_4c6ec_00013   PENDING            0.6             16   [150, 150, 150]   0.001                                                                 |\n",
            "| train_model_4c6ec_00014   PENDING            0.6             24   [150, 150, 150]   0.001                                                                 |\n",
            "| train_model_4c6ec_00015   PENDING            0.8              8   [150, 150, 150]   0.01                                                                  |\n",
            "| train_model_4c6ec_00016   PENDING            0.5             16   [150, 150, 150]   0.01                                                                  |\n",
            "| train_model_4c6ec_00017   PENDING            0.6             24   [150, 150, 150]   0.01                                                                  |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_model_4c6ec_00003 finished iteration 1 at 2023-10-17 19:44:06. Total running time: 1min 40s\n",
            "+--------------------------------------------------+\n",
            "| Trial train_model_4c6ec_00003 result             |\n",
            "+--------------------------------------------------+\n",
            "| checkpoint_dir_name                              |\n",
            "| time_this_iter_s                         16.5421 |\n",
            "| time_total_s                             16.5421 |\n",
            "| training_iteration                             1 |\n",
            "| accuracy                                 0.59225 |\n",
            "| f1_score                                 0.54753 |\n",
            "| loss                                     1.54214 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial train_model_4c6ec_00003 completed after 1 iterations at 2023-10-17 19:44:06. Total running time: 1min 40s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=3407)\u001b[0m 2023-10-17 19:44:14.259130: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial train_model_4c6ec_00004 started with configuration:\n",
            "+---------------------------------------------------------------+\n",
            "| Trial train_model_4c6ec_00004 config                          |\n",
            "+---------------------------------------------------------------+\n",
            "| batch_size                                                 16 |\n",
            "| dropout                                                   0.6 |\n",
            "| filter_sizes                                        [3, 4, 5] |\n",
            "| lr                                                      0.001 |\n",
            "| num_filters                                   [100, 100, 100] |\n",
            "| train                                                    True |\n",
            "| train_data                               ...rows x 2 columns] |\n",
            "| val_data                                 ...rows x 2 columns] |\n",
            "+---------------------------------------------------------------+\n",
            "\n",
            "Trial train_model_4c6ec_00004 finished iteration 1 at 2023-10-17 19:44:26. Total running time: 2min 0s\n",
            "+--------------------------------------------------+\n",
            "| Trial train_model_4c6ec_00004 result             |\n",
            "+--------------------------------------------------+\n",
            "| checkpoint_dir_name                              |\n",
            "| time_this_iter_s                         9.58814 |\n",
            "| time_total_s                             9.58814 |\n",
            "| training_iteration                             1 |\n",
            "| accuracy                                 0.58075 |\n",
            "| f1_score                                 0.47636 |\n",
            "| loss                                     1.84645 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial train_model_4c6ec_00004 completed after 1 iterations at 2023-10-17 19:44:26. Total running time: 2min 0s\n",
            "\n",
            "Trial status: 5 TERMINATED | 13 PENDING\n",
            "Current time: 2023-10-17 19:44:31. Total running time: 2min 5s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:None)\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         dropout     batch_size   num_filters          lr     iter     total time (s)        loss     accuracy     f1_score |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_model_4c6ec_00000   TERMINATED         0.6              8   [100, 100, 100]   0.1          1           16.8675    692.174       0.450267     0.371838 |\n",
            "| train_model_4c6ec_00001   TERMINATED         0.6             16   [100, 100, 100]   0.1          1           10.8714    408.001       0.471123     0.435003 |\n",
            "| train_model_4c6ec_00002   TERMINATED         0.5             24   [100, 100, 100]   0.1          1            6.95201   253.299       0.457754     0.354213 |\n",
            "| train_model_4c6ec_00003   TERMINATED         0.8              8   [100, 100, 100]   0.001        1           16.5421      1.54214     0.592246     0.547532 |\n",
            "| train_model_4c6ec_00004   TERMINATED         0.6             16   [100, 100, 100]   0.001        1            9.58814     1.84645     0.580749     0.476362 |\n",
            "| train_model_4c6ec_00005   PENDING            0.5             24   [100, 100, 100]   0.001                                                                   |\n",
            "| train_model_4c6ec_00006   PENDING            0.5              8   [100, 100, 100]   0.01                                                                    |\n",
            "| train_model_4c6ec_00007   PENDING            0.5             16   [100, 100, 100]   0.01                                                                    |\n",
            "| train_model_4c6ec_00008   PENDING            0.6             24   [100, 100, 100]   0.01                                                                    |\n",
            "| train_model_4c6ec_00009   PENDING            0.8              8   [150, 150, 150]   0.1                                                                     |\n",
            "| train_model_4c6ec_00010   PENDING            0.6             16   [150, 150, 150]   0.1                                                                     |\n",
            "| train_model_4c6ec_00011   PENDING            0.5             24   [150, 150, 150]   0.1                                                                     |\n",
            "| train_model_4c6ec_00012   PENDING            0.8              8   [150, 150, 150]   0.001                                                                   |\n",
            "| train_model_4c6ec_00013   PENDING            0.6             16   [150, 150, 150]   0.001                                                                   |\n",
            "| train_model_4c6ec_00014   PENDING            0.6             24   [150, 150, 150]   0.001                                                                   |\n",
            "| train_model_4c6ec_00015   PENDING            0.8              8   [150, 150, 150]   0.01                                                                    |\n",
            "| train_model_4c6ec_00016   PENDING            0.5             16   [150, 150, 150]   0.01                                                                    |\n",
            "| train_model_4c6ec_00017   PENDING            0.6             24   [150, 150, 150]   0.01                                                                    |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=3552)\u001b[0m 2023-10-17 19:44:35.311785: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial train_model_4c6ec_00005 started with configuration:\n",
            "+---------------------------------------------------------------+\n",
            "| Trial train_model_4c6ec_00005 config                          |\n",
            "+---------------------------------------------------------------+\n",
            "| batch_size                                                 24 |\n",
            "| dropout                                                   0.5 |\n",
            "| filter_sizes                                        [3, 4, 5] |\n",
            "| lr                                                      0.001 |\n",
            "| num_filters                                   [100, 100, 100] |\n",
            "| train                                                    True |\n",
            "| train_data                               ...rows x 2 columns] |\n",
            "| val_data                                 ...rows x 2 columns] |\n",
            "+---------------------------------------------------------------+\n",
            "\n",
            "Trial train_model_4c6ec_00005 finished iteration 1 at 2023-10-17 19:44:45. Total running time: 2min 19s\n",
            "+--------------------------------------------------+\n",
            "| Trial train_model_4c6ec_00005 result             |\n",
            "+--------------------------------------------------+\n",
            "| checkpoint_dir_name                              |\n",
            "| time_this_iter_s                           7.301 |\n",
            "| time_total_s                               7.301 |\n",
            "| training_iteration                             1 |\n",
            "| accuracy                                 0.62754 |\n",
            "| f1_score                                 0.58451 |\n",
            "| loss                                     1.33195 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial train_model_4c6ec_00005 completed after 1 iterations at 2023-10-17 19:44:45. Total running time: 2min 19s\n",
            "\n",
            "Trial status: 6 TERMINATED | 12 PENDING\n",
            "Current time: 2023-10-17 19:45:01. Total running time: 2min 35s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:None)\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         dropout     batch_size   num_filters          lr     iter     total time (s)        loss     accuracy     f1_score |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_model_4c6ec_00000   TERMINATED         0.6              8   [100, 100, 100]   0.1          1           16.8675    692.174       0.450267     0.371838 |\n",
            "| train_model_4c6ec_00001   TERMINATED         0.6             16   [100, 100, 100]   0.1          1           10.8714    408.001       0.471123     0.435003 |\n",
            "| train_model_4c6ec_00002   TERMINATED         0.5             24   [100, 100, 100]   0.1          1            6.95201   253.299       0.457754     0.354213 |\n",
            "| train_model_4c6ec_00003   TERMINATED         0.8              8   [100, 100, 100]   0.001        1           16.5421      1.54214     0.592246     0.547532 |\n",
            "| train_model_4c6ec_00004   TERMINATED         0.6             16   [100, 100, 100]   0.001        1            9.58814     1.84645     0.580749     0.476362 |\n",
            "| train_model_4c6ec_00005   TERMINATED         0.5             24   [100, 100, 100]   0.001        1            7.301       1.33195     0.62754      0.584508 |\n",
            "| train_model_4c6ec_00006   PENDING            0.5              8   [100, 100, 100]   0.01                                                                    |\n",
            "| train_model_4c6ec_00007   PENDING            0.5             16   [100, 100, 100]   0.01                                                                    |\n",
            "| train_model_4c6ec_00008   PENDING            0.6             24   [100, 100, 100]   0.01                                                                    |\n",
            "| train_model_4c6ec_00009   PENDING            0.8              8   [150, 150, 150]   0.1                                                                     |\n",
            "| train_model_4c6ec_00010   PENDING            0.6             16   [150, 150, 150]   0.1                                                                     |\n",
            "| train_model_4c6ec_00011   PENDING            0.5             24   [150, 150, 150]   0.1                                                                     |\n",
            "| train_model_4c6ec_00012   PENDING            0.8              8   [150, 150, 150]   0.001                                                                   |\n",
            "| train_model_4c6ec_00013   PENDING            0.6             16   [150, 150, 150]   0.001                                                                   |\n",
            "| train_model_4c6ec_00014   PENDING            0.6             24   [150, 150, 150]   0.001                                                                   |\n",
            "| train_model_4c6ec_00015   PENDING            0.8              8   [150, 150, 150]   0.01                                                                    |\n",
            "| train_model_4c6ec_00016   PENDING            0.5             16   [150, 150, 150]   0.01                                                                    |\n",
            "| train_model_4c6ec_00017   PENDING            0.6             24   [150, 150, 150]   0.01                                                                    |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=3695)\u001b[0m 2023-10-17 19:45:03.686587: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial train_model_4c6ec_00006 started with configuration:\n",
            "+---------------------------------------------------------------+\n",
            "| Trial train_model_4c6ec_00006 config                          |\n",
            "+---------------------------------------------------------------+\n",
            "| batch_size                                                  8 |\n",
            "| dropout                                                   0.5 |\n",
            "| filter_sizes                                        [3, 4, 5] |\n",
            "| lr                                                       0.01 |\n",
            "| num_filters                                   [100, 100, 100] |\n",
            "| train                                                    True |\n",
            "| train_data                               ...rows x 2 columns] |\n",
            "| val_data                                 ...rows x 2 columns] |\n",
            "+---------------------------------------------------------------+\n",
            "\n",
            "Trial train_model_4c6ec_00006 finished iteration 1 at 2023-10-17 19:45:27. Total running time: 3min 1s\n",
            "+--------------------------------------------------+\n",
            "| Trial train_model_4c6ec_00006 result             |\n",
            "+--------------------------------------------------+\n",
            "| checkpoint_dir_name                              |\n",
            "| time_this_iter_s                         18.8455 |\n",
            "| time_total_s                             18.8455 |\n",
            "| training_iteration                             1 |\n",
            "| accuracy                                 0.58102 |\n",
            "| f1_score                                 0.49547 |\n",
            "| loss                                     38.6437 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial train_model_4c6ec_00006 completed after 1 iterations at 2023-10-17 19:45:27. Total running time: 3min 1s\n",
            "\n",
            "Trial status: 7 TERMINATED | 11 PENDING\n",
            "Current time: 2023-10-17 19:45:31. Total running time: 3min 5s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:None)\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         dropout     batch_size   num_filters          lr     iter     total time (s)        loss     accuracy     f1_score |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_model_4c6ec_00000   TERMINATED         0.6              8   [100, 100, 100]   0.1          1           16.8675    692.174       0.450267     0.371838 |\n",
            "| train_model_4c6ec_00001   TERMINATED         0.6             16   [100, 100, 100]   0.1          1           10.8714    408.001       0.471123     0.435003 |\n",
            "| train_model_4c6ec_00002   TERMINATED         0.5             24   [100, 100, 100]   0.1          1            6.95201   253.299       0.457754     0.354213 |\n",
            "| train_model_4c6ec_00003   TERMINATED         0.8              8   [100, 100, 100]   0.001        1           16.5421      1.54214     0.592246     0.547532 |\n",
            "| train_model_4c6ec_00004   TERMINATED         0.6             16   [100, 100, 100]   0.001        1            9.58814     1.84645     0.580749     0.476362 |\n",
            "| train_model_4c6ec_00005   TERMINATED         0.5             24   [100, 100, 100]   0.001        1            7.301       1.33195     0.62754      0.584508 |\n",
            "| train_model_4c6ec_00006   TERMINATED         0.5              8   [100, 100, 100]   0.01         1           18.8455     38.6437      0.581016     0.495474 |\n",
            "| train_model_4c6ec_00007   PENDING            0.5             16   [100, 100, 100]   0.01                                                                    |\n",
            "| train_model_4c6ec_00008   PENDING            0.6             24   [100, 100, 100]   0.01                                                                    |\n",
            "| train_model_4c6ec_00009   PENDING            0.8              8   [150, 150, 150]   0.1                                                                     |\n",
            "| train_model_4c6ec_00010   PENDING            0.6             16   [150, 150, 150]   0.1                                                                     |\n",
            "| train_model_4c6ec_00011   PENDING            0.5             24   [150, 150, 150]   0.1                                                                     |\n",
            "| train_model_4c6ec_00012   PENDING            0.8              8   [150, 150, 150]   0.001                                                                   |\n",
            "| train_model_4c6ec_00013   PENDING            0.6             16   [150, 150, 150]   0.001                                                                   |\n",
            "| train_model_4c6ec_00014   PENDING            0.6             24   [150, 150, 150]   0.001                                                                   |\n",
            "| train_model_4c6ec_00015   PENDING            0.8              8   [150, 150, 150]   0.01                                                                    |\n",
            "| train_model_4c6ec_00016   PENDING            0.5             16   [150, 150, 150]   0.01                                                                    |\n",
            "| train_model_4c6ec_00017   PENDING            0.6             24   [150, 150, 150]   0.01                                                                    |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=3928)\u001b[0m 2023-10-17 19:45:36.737784: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial train_model_4c6ec_00007 started with configuration:\n",
            "+---------------------------------------------------------------+\n",
            "| Trial train_model_4c6ec_00007 config                          |\n",
            "+---------------------------------------------------------------+\n",
            "| batch_size                                                 16 |\n",
            "| dropout                                                   0.5 |\n",
            "| filter_sizes                                        [3, 4, 5] |\n",
            "| lr                                                       0.01 |\n",
            "| num_filters                                   [100, 100, 100] |\n",
            "| train                                                    True |\n",
            "| train_data                               ...rows x 2 columns] |\n",
            "| val_data                                 ...rows x 2 columns] |\n",
            "+---------------------------------------------------------------+\n",
            "\n",
            "Trial train_model_4c6ec_00007 finished iteration 1 at 2023-10-17 19:45:49. Total running time: 3min 23s\n",
            "+--------------------------------------------------+\n",
            "| Trial train_model_4c6ec_00007 result             |\n",
            "+--------------------------------------------------+\n",
            "| checkpoint_dir_name                              |\n",
            "| time_this_iter_s                         9.24247 |\n",
            "| time_total_s                             9.24247 |\n",
            "| training_iteration                             1 |\n",
            "| accuracy                                 0.57139 |\n",
            "| f1_score                                  0.4672 |\n",
            "| loss                                     23.7446 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial train_model_4c6ec_00007 completed after 1 iterations at 2023-10-17 19:45:49. Total running time: 3min 23s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=4087)\u001b[0m 2023-10-17 19:45:56.272023: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial train_model_4c6ec_00008 started with configuration:\n",
            "+---------------------------------------------------------------+\n",
            "| Trial train_model_4c6ec_00008 config                          |\n",
            "+---------------------------------------------------------------+\n",
            "| batch_size                                                 24 |\n",
            "| dropout                                                   0.6 |\n",
            "| filter_sizes                                        [3, 4, 5] |\n",
            "| lr                                                       0.01 |\n",
            "| num_filters                                   [100, 100, 100] |\n",
            "| train                                                    True |\n",
            "| train_data                               ...rows x 2 columns] |\n",
            "| val_data                                 ...rows x 2 columns] |\n",
            "+---------------------------------------------------------------+\n",
            "\n",
            "Trial status: 8 TERMINATED | 1 RUNNING | 9 PENDING\n",
            "Current time: 2023-10-17 19:46:01. Total running time: 3min 36s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:None)\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         dropout     batch_size   num_filters          lr     iter     total time (s)        loss     accuracy     f1_score |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_model_4c6ec_00008   RUNNING            0.6             24   [100, 100, 100]   0.01                                                                    |\n",
            "| train_model_4c6ec_00000   TERMINATED         0.6              8   [100, 100, 100]   0.1          1           16.8675    692.174       0.450267     0.371838 |\n",
            "| train_model_4c6ec_00001   TERMINATED         0.6             16   [100, 100, 100]   0.1          1           10.8714    408.001       0.471123     0.435003 |\n",
            "| train_model_4c6ec_00002   TERMINATED         0.5             24   [100, 100, 100]   0.1          1            6.95201   253.299       0.457754     0.354213 |\n",
            "| train_model_4c6ec_00003   TERMINATED         0.8              8   [100, 100, 100]   0.001        1           16.5421      1.54214     0.592246     0.547532 |\n",
            "| train_model_4c6ec_00004   TERMINATED         0.6             16   [100, 100, 100]   0.001        1            9.58814     1.84645     0.580749     0.476362 |\n",
            "| train_model_4c6ec_00005   TERMINATED         0.5             24   [100, 100, 100]   0.001        1            7.301       1.33195     0.62754      0.584508 |\n",
            "| train_model_4c6ec_00006   TERMINATED         0.5              8   [100, 100, 100]   0.01         1           18.8455     38.6437      0.581016     0.495474 |\n",
            "| train_model_4c6ec_00007   TERMINATED         0.5             16   [100, 100, 100]   0.01         1            9.24247    23.7446      0.57139      0.467205 |\n",
            "| train_model_4c6ec_00009   PENDING            0.8              8   [150, 150, 150]   0.1                                                                     |\n",
            "| train_model_4c6ec_00010   PENDING            0.6             16   [150, 150, 150]   0.1                                                                     |\n",
            "| train_model_4c6ec_00011   PENDING            0.5             24   [150, 150, 150]   0.1                                                                     |\n",
            "| train_model_4c6ec_00012   PENDING            0.8              8   [150, 150, 150]   0.001                                                                   |\n",
            "| train_model_4c6ec_00013   PENDING            0.6             16   [150, 150, 150]   0.001                                                                   |\n",
            "| train_model_4c6ec_00014   PENDING            0.6             24   [150, 150, 150]   0.001                                                                   |\n",
            "| train_model_4c6ec_00015   PENDING            0.8              8   [150, 150, 150]   0.01                                                                    |\n",
            "| train_model_4c6ec_00016   PENDING            0.5             16   [150, 150, 150]   0.01                                                                    |\n",
            "| train_model_4c6ec_00017   PENDING            0.6             24   [150, 150, 150]   0.01                                                                    |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_model_4c6ec_00008 finished iteration 1 at 2023-10-17 19:46:06. Total running time: 3min 40s\n",
            "+--------------------------------------------------+\n",
            "| Trial train_model_4c6ec_00008 result             |\n",
            "+--------------------------------------------------+\n",
            "| checkpoint_dir_name                              |\n",
            "| time_this_iter_s                         7.35456 |\n",
            "| time_total_s                             7.35456 |\n",
            "| training_iteration                             1 |\n",
            "| accuracy                                 0.60615 |\n",
            "| f1_score                                 0.48049 |\n",
            "| loss                                      12.118 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial train_model_4c6ec_00008 completed after 1 iterations at 2023-10-17 19:46:06. Total running time: 3min 40s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=4216)\u001b[0m 2023-10-17 19:46:12.886648: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial train_model_4c6ec_00009 started with configuration:\n",
            "+---------------------------------------------------------------+\n",
            "| Trial train_model_4c6ec_00009 config                          |\n",
            "+---------------------------------------------------------------+\n",
            "| batch_size                                                  8 |\n",
            "| dropout                                                   0.8 |\n",
            "| filter_sizes                                        [3, 4, 5] |\n",
            "| lr                                                        0.1 |\n",
            "| num_filters                                   [150, 150, 150] |\n",
            "| train                                                    True |\n",
            "| train_data                               ...rows x 2 columns] |\n",
            "| val_data                                 ...rows x 2 columns] |\n",
            "+---------------------------------------------------------------+\n",
            "\n",
            "Trial status: 9 TERMINATED | 1 RUNNING | 8 PENDING\n",
            "Current time: 2023-10-17 19:46:32. Total running time: 4min 6s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:None)\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         dropout     batch_size   num_filters          lr     iter     total time (s)        loss     accuracy     f1_score |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_model_4c6ec_00009   RUNNING            0.8              8   [150, 150, 150]   0.1                                                                     |\n",
            "| train_model_4c6ec_00000   TERMINATED         0.6              8   [100, 100, 100]   0.1          1           16.8675    692.174       0.450267     0.371838 |\n",
            "| train_model_4c6ec_00001   TERMINATED         0.6             16   [100, 100, 100]   0.1          1           10.8714    408.001       0.471123     0.435003 |\n",
            "| train_model_4c6ec_00002   TERMINATED         0.5             24   [100, 100, 100]   0.1          1            6.95201   253.299       0.457754     0.354213 |\n",
            "| train_model_4c6ec_00003   TERMINATED         0.8              8   [100, 100, 100]   0.001        1           16.5421      1.54214     0.592246     0.547532 |\n",
            "| train_model_4c6ec_00004   TERMINATED         0.6             16   [100, 100, 100]   0.001        1            9.58814     1.84645     0.580749     0.476362 |\n",
            "| train_model_4c6ec_00005   TERMINATED         0.5             24   [100, 100, 100]   0.001        1            7.301       1.33195     0.62754      0.584508 |\n",
            "| train_model_4c6ec_00006   TERMINATED         0.5              8   [100, 100, 100]   0.01         1           18.8455     38.6437      0.581016     0.495474 |\n",
            "| train_model_4c6ec_00007   TERMINATED         0.5             16   [100, 100, 100]   0.01         1            9.24247    23.7446      0.57139      0.467205 |\n",
            "| train_model_4c6ec_00008   TERMINATED         0.6             24   [100, 100, 100]   0.01         1            7.35456    12.118       0.60615      0.480486 |\n",
            "| train_model_4c6ec_00010   PENDING            0.6             16   [150, 150, 150]   0.1                                                                     |\n",
            "| train_model_4c6ec_00011   PENDING            0.5             24   [150, 150, 150]   0.1                                                                     |\n",
            "| train_model_4c6ec_00012   PENDING            0.8              8   [150, 150, 150]   0.001                                                                   |\n",
            "| train_model_4c6ec_00013   PENDING            0.6             16   [150, 150, 150]   0.001                                                                   |\n",
            "| train_model_4c6ec_00014   PENDING            0.6             24   [150, 150, 150]   0.001                                                                   |\n",
            "| train_model_4c6ec_00015   PENDING            0.8              8   [150, 150, 150]   0.01                                                                    |\n",
            "| train_model_4c6ec_00016   PENDING            0.5             16   [150, 150, 150]   0.01                                                                    |\n",
            "| train_model_4c6ec_00017   PENDING            0.6             24   [150, 150, 150]   0.01                                                                    |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_model_4c6ec_00009 finished iteration 1 at 2023-10-17 19:46:44. Total running time: 4min 18s\n",
            "+--------------------------------------------------+\n",
            "| Trial train_model_4c6ec_00009 result             |\n",
            "+--------------------------------------------------+\n",
            "| checkpoint_dir_name                              |\n",
            "| time_this_iter_s                         28.6971 |\n",
            "| time_total_s                             28.6971 |\n",
            "| training_iteration                             1 |\n",
            "| accuracy                                 0.44626 |\n",
            "| f1_score                                  0.3228 |\n",
            "| loss                                     1566.06 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial train_model_4c6ec_00009 completed after 1 iterations at 2023-10-17 19:46:44. Total running time: 4min 18s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=4439)\u001b[0m 2023-10-17 19:46:52.707385: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial train_model_4c6ec_00010 started with configuration:\n",
            "+---------------------------------------------------------------+\n",
            "| Trial train_model_4c6ec_00010 config                          |\n",
            "+---------------------------------------------------------------+\n",
            "| batch_size                                                 16 |\n",
            "| dropout                                                   0.6 |\n",
            "| filter_sizes                                        [3, 4, 5] |\n",
            "| lr                                                        0.1 |\n",
            "| num_filters                                   [150, 150, 150] |\n",
            "| train                                                    True |\n",
            "| train_data                               ...rows x 2 columns] |\n",
            "| val_data                                 ...rows x 2 columns] |\n",
            "+---------------------------------------------------------------+\n",
            "\n",
            "Trial status: 10 TERMINATED | 1 RUNNING | 7 PENDING\n",
            "Current time: 2023-10-17 19:47:02. Total running time: 4min 36s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:None)\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         dropout     batch_size   num_filters          lr     iter     total time (s)         loss     accuracy     f1_score |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_model_4c6ec_00010   RUNNING            0.6             16   [150, 150, 150]   0.1                                                                      |\n",
            "| train_model_4c6ec_00000   TERMINATED         0.6              8   [100, 100, 100]   0.1          1           16.8675     692.174       0.450267     0.371838 |\n",
            "| train_model_4c6ec_00001   TERMINATED         0.6             16   [100, 100, 100]   0.1          1           10.8714     408.001       0.471123     0.435003 |\n",
            "| train_model_4c6ec_00002   TERMINATED         0.5             24   [100, 100, 100]   0.1          1            6.95201    253.299       0.457754     0.354213 |\n",
            "| train_model_4c6ec_00003   TERMINATED         0.8              8   [100, 100, 100]   0.001        1           16.5421       1.54214     0.592246     0.547532 |\n",
            "| train_model_4c6ec_00004   TERMINATED         0.6             16   [100, 100, 100]   0.001        1            9.58814      1.84645     0.580749     0.476362 |\n",
            "| train_model_4c6ec_00005   TERMINATED         0.5             24   [100, 100, 100]   0.001        1            7.301        1.33195     0.62754      0.584508 |\n",
            "| train_model_4c6ec_00006   TERMINATED         0.5              8   [100, 100, 100]   0.01         1           18.8455      38.6437      0.581016     0.495474 |\n",
            "| train_model_4c6ec_00007   TERMINATED         0.5             16   [100, 100, 100]   0.01         1            9.24247     23.7446      0.57139      0.467205 |\n",
            "| train_model_4c6ec_00008   TERMINATED         0.6             24   [100, 100, 100]   0.01         1            7.35456     12.118       0.60615      0.480486 |\n",
            "| train_model_4c6ec_00009   TERMINATED         0.8              8   [150, 150, 150]   0.1          1           28.6971    1566.06        0.446257     0.322799 |\n",
            "| train_model_4c6ec_00011   PENDING            0.5             24   [150, 150, 150]   0.1                                                                      |\n",
            "| train_model_4c6ec_00012   PENDING            0.8              8   [150, 150, 150]   0.001                                                                    |\n",
            "| train_model_4c6ec_00013   PENDING            0.6             16   [150, 150, 150]   0.001                                                                    |\n",
            "| train_model_4c6ec_00014   PENDING            0.6             24   [150, 150, 150]   0.001                                                                    |\n",
            "| train_model_4c6ec_00015   PENDING            0.8              8   [150, 150, 150]   0.01                                                                     |\n",
            "| train_model_4c6ec_00016   PENDING            0.5             16   [150, 150, 150]   0.01                                                                     |\n",
            "| train_model_4c6ec_00017   PENDING            0.6             24   [150, 150, 150]   0.01                                                                     |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_model_4c6ec_00010 finished iteration 1 at 2023-10-17 19:47:04. Total running time: 4min 38s\n",
            "+--------------------------------------------------+\n",
            "| Trial train_model_4c6ec_00010 result             |\n",
            "+--------------------------------------------------+\n",
            "| checkpoint_dir_name                              |\n",
            "| time_this_iter_s                         8.58185 |\n",
            "| time_total_s                             8.58185 |\n",
            "| training_iteration                             1 |\n",
            "| accuracy                                 0.48556 |\n",
            "| f1_score                                 0.45468 |\n",
            "| loss                                     848.314 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial train_model_4c6ec_00010 completed after 1 iterations at 2023-10-17 19:47:04. Total running time: 4min 38s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=4584)\u001b[0m 2023-10-17 19:47:15.168001: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial train_model_4c6ec_00011 started with configuration:\n",
            "+---------------------------------------------------------------+\n",
            "| Trial train_model_4c6ec_00011 config                          |\n",
            "+---------------------------------------------------------------+\n",
            "| batch_size                                                 24 |\n",
            "| dropout                                                   0.5 |\n",
            "| filter_sizes                                        [3, 4, 5] |\n",
            "| lr                                                        0.1 |\n",
            "| num_filters                                   [150, 150, 150] |\n",
            "| train                                                    True |\n",
            "| train_data                               ...rows x 2 columns] |\n",
            "| val_data                                 ...rows x 2 columns] |\n",
            "+---------------------------------------------------------------+\n",
            "\n",
            "Trial train_model_4c6ec_00011 finished iteration 1 at 2023-10-17 19:47:24. Total running time: 4min 58s\n",
            "+--------------------------------------------------+\n",
            "| Trial train_model_4c6ec_00011 result             |\n",
            "+--------------------------------------------------+\n",
            "| checkpoint_dir_name                              |\n",
            "| time_this_iter_s                         6.98915 |\n",
            "| time_total_s                             6.98915 |\n",
            "| training_iteration                             1 |\n",
            "| accuracy                                 0.47807 |\n",
            "| f1_score                                 0.36754 |\n",
            "| loss                                     369.768 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial train_model_4c6ec_00011 completed after 1 iterations at 2023-10-17 19:47:24. Total running time: 4min 58s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=4731)\u001b[0m 2023-10-17 19:47:32.074052: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial status: 12 TERMINATED | 6 PENDING\n",
            "Current time: 2023-10-17 19:47:32. Total running time: 5min 6s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:None)\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         dropout     batch_size   num_filters          lr     iter     total time (s)         loss     accuracy     f1_score |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_model_4c6ec_00000   TERMINATED         0.6              8   [100, 100, 100]   0.1          1           16.8675     692.174       0.450267     0.371838 |\n",
            "| train_model_4c6ec_00001   TERMINATED         0.6             16   [100, 100, 100]   0.1          1           10.8714     408.001       0.471123     0.435003 |\n",
            "| train_model_4c6ec_00002   TERMINATED         0.5             24   [100, 100, 100]   0.1          1            6.95201    253.299       0.457754     0.354213 |\n",
            "| train_model_4c6ec_00003   TERMINATED         0.8              8   [100, 100, 100]   0.001        1           16.5421       1.54214     0.592246     0.547532 |\n",
            "| train_model_4c6ec_00004   TERMINATED         0.6             16   [100, 100, 100]   0.001        1            9.58814      1.84645     0.580749     0.476362 |\n",
            "| train_model_4c6ec_00005   TERMINATED         0.5             24   [100, 100, 100]   0.001        1            7.301        1.33195     0.62754      0.584508 |\n",
            "| train_model_4c6ec_00006   TERMINATED         0.5              8   [100, 100, 100]   0.01         1           18.8455      38.6437      0.581016     0.495474 |\n",
            "| train_model_4c6ec_00007   TERMINATED         0.5             16   [100, 100, 100]   0.01         1            9.24247     23.7446      0.57139      0.467205 |\n",
            "| train_model_4c6ec_00008   TERMINATED         0.6             24   [100, 100, 100]   0.01         1            7.35456     12.118       0.60615      0.480486 |\n",
            "| train_model_4c6ec_00009   TERMINATED         0.8              8   [150, 150, 150]   0.1          1           28.6971    1566.06        0.446257     0.322799 |\n",
            "| train_model_4c6ec_00010   TERMINATED         0.6             16   [150, 150, 150]   0.1          1            8.58185    848.314       0.485561     0.454677 |\n",
            "| train_model_4c6ec_00011   TERMINATED         0.5             24   [150, 150, 150]   0.1          1            6.98915    369.768       0.478075     0.367543 |\n",
            "| train_model_4c6ec_00012   PENDING            0.8              8   [150, 150, 150]   0.001                                                                    |\n",
            "| train_model_4c6ec_00013   PENDING            0.6             16   [150, 150, 150]   0.001                                                                    |\n",
            "| train_model_4c6ec_00014   PENDING            0.6             24   [150, 150, 150]   0.001                                                                    |\n",
            "| train_model_4c6ec_00015   PENDING            0.8              8   [150, 150, 150]   0.01                                                                     |\n",
            "| train_model_4c6ec_00016   PENDING            0.5             16   [150, 150, 150]   0.01                                                                     |\n",
            "| train_model_4c6ec_00017   PENDING            0.6             24   [150, 150, 150]   0.01                                                                     |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_model_4c6ec_00012 started with configuration:\n",
            "+---------------------------------------------------------------+\n",
            "| Trial train_model_4c6ec_00012 config                          |\n",
            "+---------------------------------------------------------------+\n",
            "| batch_size                                                  8 |\n",
            "| dropout                                                   0.8 |\n",
            "| filter_sizes                                        [3, 4, 5] |\n",
            "| lr                                                      0.001 |\n",
            "| num_filters                                   [150, 150, 150] |\n",
            "| train                                                    True |\n",
            "| train_data                               ...rows x 2 columns] |\n",
            "| val_data                                 ...rows x 2 columns] |\n",
            "+---------------------------------------------------------------+\n",
            "\n",
            "Trial train_model_4c6ec_00012 finished iteration 1 at 2023-10-17 19:47:51. Total running time: 5min 25s\n",
            "+--------------------------------------------------+\n",
            "| Trial train_model_4c6ec_00012 result             |\n",
            "+--------------------------------------------------+\n",
            "| checkpoint_dir_name                              |\n",
            "| time_this_iter_s                         16.8165 |\n",
            "| time_total_s                             16.8165 |\n",
            "| training_iteration                             1 |\n",
            "| accuracy                                 0.59786 |\n",
            "| f1_score                                  0.5173 |\n",
            "| loss                                      1.7425 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial train_model_4c6ec_00012 completed after 1 iterations at 2023-10-17 19:47:51. Total running time: 5min 25s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=4906)\u001b[0m 2023-10-17 19:47:59.958139: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial status: 13 TERMINATED | 5 PENDING\n",
            "Current time: 2023-10-17 19:48:02. Total running time: 5min 36s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:None)\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         dropout     batch_size   num_filters          lr     iter     total time (s)         loss     accuracy     f1_score |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_model_4c6ec_00000   TERMINATED         0.6              8   [100, 100, 100]   0.1          1           16.8675     692.174       0.450267     0.371838 |\n",
            "| train_model_4c6ec_00001   TERMINATED         0.6             16   [100, 100, 100]   0.1          1           10.8714     408.001       0.471123     0.435003 |\n",
            "| train_model_4c6ec_00002   TERMINATED         0.5             24   [100, 100, 100]   0.1          1            6.95201    253.299       0.457754     0.354213 |\n",
            "| train_model_4c6ec_00003   TERMINATED         0.8              8   [100, 100, 100]   0.001        1           16.5421       1.54214     0.592246     0.547532 |\n",
            "| train_model_4c6ec_00004   TERMINATED         0.6             16   [100, 100, 100]   0.001        1            9.58814      1.84645     0.580749     0.476362 |\n",
            "| train_model_4c6ec_00005   TERMINATED         0.5             24   [100, 100, 100]   0.001        1            7.301        1.33195     0.62754      0.584508 |\n",
            "| train_model_4c6ec_00006   TERMINATED         0.5              8   [100, 100, 100]   0.01         1           18.8455      38.6437      0.581016     0.495474 |\n",
            "| train_model_4c6ec_00007   TERMINATED         0.5             16   [100, 100, 100]   0.01         1            9.24247     23.7446      0.57139      0.467205 |\n",
            "| train_model_4c6ec_00008   TERMINATED         0.6             24   [100, 100, 100]   0.01         1            7.35456     12.118       0.60615      0.480486 |\n",
            "| train_model_4c6ec_00009   TERMINATED         0.8              8   [150, 150, 150]   0.1          1           28.6971    1566.06        0.446257     0.322799 |\n",
            "| train_model_4c6ec_00010   TERMINATED         0.6             16   [150, 150, 150]   0.1          1            8.58185    848.314       0.485561     0.454677 |\n",
            "| train_model_4c6ec_00011   TERMINATED         0.5             24   [150, 150, 150]   0.1          1            6.98915    369.768       0.478075     0.367543 |\n",
            "| train_model_4c6ec_00012   TERMINATED         0.8              8   [150, 150, 150]   0.001        1           16.8165       1.7425      0.597861     0.517295 |\n",
            "| train_model_4c6ec_00013   PENDING            0.6             16   [150, 150, 150]   0.001                                                                    |\n",
            "| train_model_4c6ec_00014   PENDING            0.6             24   [150, 150, 150]   0.001                                                                    |\n",
            "| train_model_4c6ec_00015   PENDING            0.8              8   [150, 150, 150]   0.01                                                                     |\n",
            "| train_model_4c6ec_00016   PENDING            0.5             16   [150, 150, 150]   0.01                                                                     |\n",
            "| train_model_4c6ec_00017   PENDING            0.6             24   [150, 150, 150]   0.01                                                                     |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_model_4c6ec_00013 started with configuration:\n",
            "+---------------------------------------------------------------+\n",
            "| Trial train_model_4c6ec_00013 config                          |\n",
            "+---------------------------------------------------------------+\n",
            "| batch_size                                                 16 |\n",
            "| dropout                                                   0.6 |\n",
            "| filter_sizes                                        [3, 4, 5] |\n",
            "| lr                                                      0.001 |\n",
            "| num_filters                                   [150, 150, 150] |\n",
            "| train                                                    True |\n",
            "| train_data                               ...rows x 2 columns] |\n",
            "| val_data                                 ...rows x 2 columns] |\n",
            "+---------------------------------------------------------------+\n",
            "\n",
            "Trial train_model_4c6ec_00013 finished iteration 1 at 2023-10-17 19:48:11. Total running time: 5min 45s\n",
            "+--------------------------------------------------+\n",
            "| Trial train_model_4c6ec_00013 result             |\n",
            "+--------------------------------------------------+\n",
            "| checkpoint_dir_name                              |\n",
            "| time_this_iter_s                         9.33729 |\n",
            "| time_total_s                             9.33729 |\n",
            "| training_iteration                             1 |\n",
            "| accuracy                                 0.61203 |\n",
            "| f1_score                                 0.52634 |\n",
            "| loss                                     1.51588 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial train_model_4c6ec_00013 completed after 1 iterations at 2023-10-17 19:48:11. Total running time: 5min 45s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=5053)\u001b[0m 2023-10-17 19:48:18.962481: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial train_model_4c6ec_00014 started with configuration:\n",
            "+---------------------------------------------------------------+\n",
            "| Trial train_model_4c6ec_00014 config                          |\n",
            "+---------------------------------------------------------------+\n",
            "| batch_size                                                 24 |\n",
            "| dropout                                                   0.6 |\n",
            "| filter_sizes                                        [3, 4, 5] |\n",
            "| lr                                                      0.001 |\n",
            "| num_filters                                   [150, 150, 150] |\n",
            "| train                                                    True |\n",
            "| train_data                               ...rows x 2 columns] |\n",
            "| val_data                                 ...rows x 2 columns] |\n",
            "+---------------------------------------------------------------+\n",
            "\n",
            "Trial train_model_4c6ec_00014 finished iteration 1 at 2023-10-17 19:48:30. Total running time: 6min 4s\n",
            "+--------------------------------------------------+\n",
            "| Trial train_model_4c6ec_00014 result             |\n",
            "+--------------------------------------------------+\n",
            "| checkpoint_dir_name                              |\n",
            "| time_this_iter_s                         8.30042 |\n",
            "| time_total_s                             8.30042 |\n",
            "| training_iteration                             1 |\n",
            "| accuracy                                 0.62647 |\n",
            "| f1_score                                 0.55732 |\n",
            "| loss                                     1.32958 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial train_model_4c6ec_00014 completed after 1 iterations at 2023-10-17 19:48:30. Total running time: 6min 4s\n",
            "\n",
            "Trial status: 15 TERMINATED | 3 PENDING\n",
            "Current time: 2023-10-17 19:48:32. Total running time: 6min 6s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:None)\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         dropout     batch_size   num_filters          lr     iter     total time (s)         loss     accuracy     f1_score |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_model_4c6ec_00000   TERMINATED         0.6              8   [100, 100, 100]   0.1          1           16.8675     692.174       0.450267     0.371838 |\n",
            "| train_model_4c6ec_00001   TERMINATED         0.6             16   [100, 100, 100]   0.1          1           10.8714     408.001       0.471123     0.435003 |\n",
            "| train_model_4c6ec_00002   TERMINATED         0.5             24   [100, 100, 100]   0.1          1            6.95201    253.299       0.457754     0.354213 |\n",
            "| train_model_4c6ec_00003   TERMINATED         0.8              8   [100, 100, 100]   0.001        1           16.5421       1.54214     0.592246     0.547532 |\n",
            "| train_model_4c6ec_00004   TERMINATED         0.6             16   [100, 100, 100]   0.001        1            9.58814      1.84645     0.580749     0.476362 |\n",
            "| train_model_4c6ec_00005   TERMINATED         0.5             24   [100, 100, 100]   0.001        1            7.301        1.33195     0.62754      0.584508 |\n",
            "| train_model_4c6ec_00006   TERMINATED         0.5              8   [100, 100, 100]   0.01         1           18.8455      38.6437      0.581016     0.495474 |\n",
            "| train_model_4c6ec_00007   TERMINATED         0.5             16   [100, 100, 100]   0.01         1            9.24247     23.7446      0.57139      0.467205 |\n",
            "| train_model_4c6ec_00008   TERMINATED         0.6             24   [100, 100, 100]   0.01         1            7.35456     12.118       0.60615      0.480486 |\n",
            "| train_model_4c6ec_00009   TERMINATED         0.8              8   [150, 150, 150]   0.1          1           28.6971    1566.06        0.446257     0.322799 |\n",
            "| train_model_4c6ec_00010   TERMINATED         0.6             16   [150, 150, 150]   0.1          1            8.58185    848.314       0.485561     0.454677 |\n",
            "| train_model_4c6ec_00011   TERMINATED         0.5             24   [150, 150, 150]   0.1          1            6.98915    369.768       0.478075     0.367543 |\n",
            "| train_model_4c6ec_00012   TERMINATED         0.8              8   [150, 150, 150]   0.001        1           16.8165       1.7425      0.597861     0.517295 |\n",
            "| train_model_4c6ec_00013   TERMINATED         0.6             16   [150, 150, 150]   0.001        1            9.33729      1.51588     0.612032     0.526337 |\n",
            "| train_model_4c6ec_00014   TERMINATED         0.6             24   [150, 150, 150]   0.001        1            8.30042      1.32958     0.626471     0.557321 |\n",
            "| train_model_4c6ec_00015   PENDING            0.8              8   [150, 150, 150]   0.01                                                                     |\n",
            "| train_model_4c6ec_00016   PENDING            0.5             16   [150, 150, 150]   0.01                                                                     |\n",
            "| train_model_4c6ec_00017   PENDING            0.6             24   [150, 150, 150]   0.01                                                                     |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=5188)\u001b[0m 2023-10-17 19:48:37.071191: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial train_model_4c6ec_00015 started with configuration:\n",
            "+---------------------------------------------------------------+\n",
            "| Trial train_model_4c6ec_00015 config                          |\n",
            "+---------------------------------------------------------------+\n",
            "| batch_size                                                  8 |\n",
            "| dropout                                                   0.8 |\n",
            "| filter_sizes                                        [3, 4, 5] |\n",
            "| lr                                                       0.01 |\n",
            "| num_filters                                   [150, 150, 150] |\n",
            "| train                                                    True |\n",
            "| train_data                               ...rows x 2 columns] |\n",
            "| val_data                                 ...rows x 2 columns] |\n",
            "+---------------------------------------------------------------+\n",
            "\n",
            "Trial train_model_4c6ec_00015 finished iteration 1 at 2023-10-17 19:48:59. Total running time: 6min 33s\n",
            "+--------------------------------------------------+\n",
            "| Trial train_model_4c6ec_00015 result             |\n",
            "+--------------------------------------------------+\n",
            "| checkpoint_dir_name                              |\n",
            "| time_this_iter_s                         19.1195 |\n",
            "| time_total_s                             19.1195 |\n",
            "| training_iteration                             1 |\n",
            "| accuracy                                 0.56471 |\n",
            "| f1_score                                 0.47848 |\n",
            "| loss                                     55.3698 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial train_model_4c6ec_00015 completed after 1 iterations at 2023-10-17 19:48:59. Total running time: 6min 33s\n",
            "\n",
            "Trial status: 16 TERMINATED | 2 PENDING\n",
            "Current time: 2023-10-17 19:49:02. Total running time: 6min 36s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:None)\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         dropout     batch_size   num_filters          lr     iter     total time (s)         loss     accuracy     f1_score |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_model_4c6ec_00000   TERMINATED         0.6              8   [100, 100, 100]   0.1          1           16.8675     692.174       0.450267     0.371838 |\n",
            "| train_model_4c6ec_00001   TERMINATED         0.6             16   [100, 100, 100]   0.1          1           10.8714     408.001       0.471123     0.435003 |\n",
            "| train_model_4c6ec_00002   TERMINATED         0.5             24   [100, 100, 100]   0.1          1            6.95201    253.299       0.457754     0.354213 |\n",
            "| train_model_4c6ec_00003   TERMINATED         0.8              8   [100, 100, 100]   0.001        1           16.5421       1.54214     0.592246     0.547532 |\n",
            "| train_model_4c6ec_00004   TERMINATED         0.6             16   [100, 100, 100]   0.001        1            9.58814      1.84645     0.580749     0.476362 |\n",
            "| train_model_4c6ec_00005   TERMINATED         0.5             24   [100, 100, 100]   0.001        1            7.301        1.33195     0.62754      0.584508 |\n",
            "| train_model_4c6ec_00006   TERMINATED         0.5              8   [100, 100, 100]   0.01         1           18.8455      38.6437      0.581016     0.495474 |\n",
            "| train_model_4c6ec_00007   TERMINATED         0.5             16   [100, 100, 100]   0.01         1            9.24247     23.7446      0.57139      0.467205 |\n",
            "| train_model_4c6ec_00008   TERMINATED         0.6             24   [100, 100, 100]   0.01         1            7.35456     12.118       0.60615      0.480486 |\n",
            "| train_model_4c6ec_00009   TERMINATED         0.8              8   [150, 150, 150]   0.1          1           28.6971    1566.06        0.446257     0.322799 |\n",
            "| train_model_4c6ec_00010   TERMINATED         0.6             16   [150, 150, 150]   0.1          1            8.58185    848.314       0.485561     0.454677 |\n",
            "| train_model_4c6ec_00011   TERMINATED         0.5             24   [150, 150, 150]   0.1          1            6.98915    369.768       0.478075     0.367543 |\n",
            "| train_model_4c6ec_00012   TERMINATED         0.8              8   [150, 150, 150]   0.001        1           16.8165       1.7425      0.597861     0.517295 |\n",
            "| train_model_4c6ec_00013   TERMINATED         0.6             16   [150, 150, 150]   0.001        1            9.33729      1.51588     0.612032     0.526337 |\n",
            "| train_model_4c6ec_00014   TERMINATED         0.6             24   [150, 150, 150]   0.001        1            8.30042      1.32958     0.626471     0.557321 |\n",
            "| train_model_4c6ec_00015   TERMINATED         0.8              8   [150, 150, 150]   0.01         1           19.1195      55.3698      0.564706     0.47848  |\n",
            "| train_model_4c6ec_00016   PENDING            0.5             16   [150, 150, 150]   0.01                                                                     |\n",
            "| train_model_4c6ec_00017   PENDING            0.6             24   [150, 150, 150]   0.01                                                                     |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=5375)\u001b[0m 2023-10-17 19:49:09.258906: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial train_model_4c6ec_00016 started with configuration:\n",
            "+---------------------------------------------------------------+\n",
            "| Trial train_model_4c6ec_00016 config                          |\n",
            "+---------------------------------------------------------------+\n",
            "| batch_size                                                 16 |\n",
            "| dropout                                                   0.5 |\n",
            "| filter_sizes                                        [3, 4, 5] |\n",
            "| lr                                                       0.01 |\n",
            "| num_filters                                   [150, 150, 150] |\n",
            "| train                                                    True |\n",
            "| train_data                               ...rows x 2 columns] |\n",
            "| val_data                                 ...rows x 2 columns] |\n",
            "+---------------------------------------------------------------+\n",
            "\n",
            "Trial train_model_4c6ec_00016 finished iteration 1 at 2023-10-17 19:49:22. Total running time: 6min 56s\n",
            "+--------------------------------------------------+\n",
            "| Trial train_model_4c6ec_00016 result             |\n",
            "+--------------------------------------------------+\n",
            "| checkpoint_dir_name                              |\n",
            "| time_this_iter_s                          10.535 |\n",
            "| time_total_s                              10.535 |\n",
            "| training_iteration                             1 |\n",
            "| accuracy                                 0.59626 |\n",
            "| f1_score                                 0.49967 |\n",
            "| loss                                     23.4382 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial train_model_4c6ec_00016 completed after 1 iterations at 2023-10-17 19:49:22. Total running time: 6min 56s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=5527)\u001b[0m 2023-10-17 19:49:29.018446: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial train_model_4c6ec_00017 started with configuration:\n",
            "+---------------------------------------------------------------+\n",
            "| Trial train_model_4c6ec_00017 config                          |\n",
            "+---------------------------------------------------------------+\n",
            "| batch_size                                                 24 |\n",
            "| dropout                                                   0.6 |\n",
            "| filter_sizes                                        [3, 4, 5] |\n",
            "| lr                                                       0.01 |\n",
            "| num_filters                                   [150, 150, 150] |\n",
            "| train                                                    True |\n",
            "| train_data                               ...rows x 2 columns] |\n",
            "| val_data                                 ...rows x 2 columns] |\n",
            "+---------------------------------------------------------------+\n",
            "\n",
            "Trial status: 17 TERMINATED | 1 RUNNING\n",
            "Current time: 2023-10-17 19:49:32. Total running time: 7min 6s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:None)\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         dropout     batch_size   num_filters          lr     iter     total time (s)         loss     accuracy     f1_score |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_model_4c6ec_00017   RUNNING            0.6             24   [150, 150, 150]   0.01                                                                     |\n",
            "| train_model_4c6ec_00000   TERMINATED         0.6              8   [100, 100, 100]   0.1          1           16.8675     692.174       0.450267     0.371838 |\n",
            "| train_model_4c6ec_00001   TERMINATED         0.6             16   [100, 100, 100]   0.1          1           10.8714     408.001       0.471123     0.435003 |\n",
            "| train_model_4c6ec_00002   TERMINATED         0.5             24   [100, 100, 100]   0.1          1            6.95201    253.299       0.457754     0.354213 |\n",
            "| train_model_4c6ec_00003   TERMINATED         0.8              8   [100, 100, 100]   0.001        1           16.5421       1.54214     0.592246     0.547532 |\n",
            "| train_model_4c6ec_00004   TERMINATED         0.6             16   [100, 100, 100]   0.001        1            9.58814      1.84645     0.580749     0.476362 |\n",
            "| train_model_4c6ec_00005   TERMINATED         0.5             24   [100, 100, 100]   0.001        1            7.301        1.33195     0.62754      0.584508 |\n",
            "| train_model_4c6ec_00006   TERMINATED         0.5              8   [100, 100, 100]   0.01         1           18.8455      38.6437      0.581016     0.495474 |\n",
            "| train_model_4c6ec_00007   TERMINATED         0.5             16   [100, 100, 100]   0.01         1            9.24247     23.7446      0.57139      0.467205 |\n",
            "| train_model_4c6ec_00008   TERMINATED         0.6             24   [100, 100, 100]   0.01         1            7.35456     12.118       0.60615      0.480486 |\n",
            "| train_model_4c6ec_00009   TERMINATED         0.8              8   [150, 150, 150]   0.1          1           28.6971    1566.06        0.446257     0.322799 |\n",
            "| train_model_4c6ec_00010   TERMINATED         0.6             16   [150, 150, 150]   0.1          1            8.58185    848.314       0.485561     0.454677 |\n",
            "| train_model_4c6ec_00011   TERMINATED         0.5             24   [150, 150, 150]   0.1          1            6.98915    369.768       0.478075     0.367543 |\n",
            "| train_model_4c6ec_00012   TERMINATED         0.8              8   [150, 150, 150]   0.001        1           16.8165       1.7425      0.597861     0.517295 |\n",
            "| train_model_4c6ec_00013   TERMINATED         0.6             16   [150, 150, 150]   0.001        1            9.33729      1.51588     0.612032     0.526337 |\n",
            "| train_model_4c6ec_00014   TERMINATED         0.6             24   [150, 150, 150]   0.001        1            8.30042      1.32958     0.626471     0.557321 |\n",
            "| train_model_4c6ec_00015   TERMINATED         0.8              8   [150, 150, 150]   0.01         1           19.1195      55.3698      0.564706     0.47848  |\n",
            "| train_model_4c6ec_00016   TERMINATED         0.5             16   [150, 150, 150]   0.01         1           10.535       23.4382      0.596257     0.499673 |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_model_4c6ec_00017 finished iteration 1 at 2023-10-17 19:49:40. Total running time: 7min 14s\n",
            "+--------------------------------------------------+\n",
            "| Trial train_model_4c6ec_00017 result             |\n",
            "+--------------------------------------------------+\n",
            "| checkpoint_dir_name                              |\n",
            "| time_this_iter_s                         8.14828 |\n",
            "| time_total_s                             8.14828 |\n",
            "| training_iteration                             1 |\n",
            "| accuracy                                 0.60027 |\n",
            "| f1_score                                 0.48078 |\n",
            "| loss                                     16.6042 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial train_model_4c6ec_00017 completed after 1 iterations at 2023-10-17 19:49:40. Total running time: 7min 14s\n",
            "\n",
            "Trial status: 18 TERMINATED\n",
            "Current time: 2023-10-17 19:49:40. Total running time: 7min 14s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:None)\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         dropout     batch_size   num_filters          lr     iter     total time (s)         loss     accuracy     f1_score |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_model_4c6ec_00000   TERMINATED         0.6              8   [100, 100, 100]   0.1          1           16.8675     692.174       0.450267     0.371838 |\n",
            "| train_model_4c6ec_00001   TERMINATED         0.6             16   [100, 100, 100]   0.1          1           10.8714     408.001       0.471123     0.435003 |\n",
            "| train_model_4c6ec_00002   TERMINATED         0.5             24   [100, 100, 100]   0.1          1            6.95201    253.299       0.457754     0.354213 |\n",
            "| train_model_4c6ec_00003   TERMINATED         0.8              8   [100, 100, 100]   0.001        1           16.5421       1.54214     0.592246     0.547532 |\n",
            "| train_model_4c6ec_00004   TERMINATED         0.6             16   [100, 100, 100]   0.001        1            9.58814      1.84645     0.580749     0.476362 |\n",
            "| train_model_4c6ec_00005   TERMINATED         0.5             24   [100, 100, 100]   0.001        1            7.301        1.33195     0.62754      0.584508 |\n",
            "| train_model_4c6ec_00006   TERMINATED         0.5              8   [100, 100, 100]   0.01         1           18.8455      38.6437      0.581016     0.495474 |\n",
            "| train_model_4c6ec_00007   TERMINATED         0.5             16   [100, 100, 100]   0.01         1            9.24247     23.7446      0.57139      0.467205 |\n",
            "| train_model_4c6ec_00008   TERMINATED         0.6             24   [100, 100, 100]   0.01         1            7.35456     12.118       0.60615      0.480486 |\n",
            "| train_model_4c6ec_00009   TERMINATED         0.8              8   [150, 150, 150]   0.1          1           28.6971    1566.06        0.446257     0.322799 |\n",
            "| train_model_4c6ec_00010   TERMINATED         0.6             16   [150, 150, 150]   0.1          1            8.58185    848.314       0.485561     0.454677 |\n",
            "| train_model_4c6ec_00011   TERMINATED         0.5             24   [150, 150, 150]   0.1          1            6.98915    369.768       0.478075     0.367543 |\n",
            "| train_model_4c6ec_00012   TERMINATED         0.8              8   [150, 150, 150]   0.001        1           16.8165       1.7425      0.597861     0.517295 |\n",
            "| train_model_4c6ec_00013   TERMINATED         0.6             16   [150, 150, 150]   0.001        1            9.33729      1.51588     0.612032     0.526337 |\n",
            "| train_model_4c6ec_00014   TERMINATED         0.6             24   [150, 150, 150]   0.001        1            8.30042      1.32958     0.626471     0.557321 |\n",
            "| train_model_4c6ec_00015   TERMINATED         0.8              8   [150, 150, 150]   0.01         1           19.1195      55.3698      0.564706     0.47848  |\n",
            "| train_model_4c6ec_00016   TERMINATED         0.5             16   [150, 150, 150]   0.01         1           10.535       23.4382      0.596257     0.499673 |\n",
            "| train_model_4c6ec_00017   TERMINATED         0.6             24   [150, 150, 150]   0.01         1            8.14828     16.6042      0.600267     0.480782 |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Best config:  {'train_data':                                                   tweet label\n",
            "0     “worry is a down payment on a problem you may ...     2\n",
            "1     my roommate: it's okay that we can't spell bec...     0\n",
            "2     no but that's so cute. atsu was probably shy a...     1\n",
            "3     rooneys fucking untouchable isn't he? been fuc...     0\n",
            "4     it's pretty depressing when u hit pan on ur fa...     3\n",
            "...                                                 ...   ...\n",
            "3252  i get discouraged because i try for 5 fucking ...     3\n",
            "3253  the @user are in contention and hosting @user ...     3\n",
            "3254  @user @user @user @user @user as a fellow up g...     0\n",
            "3255  you have a #problem? yes! can you do #somethin...     0\n",
            "3256  @user @user i will fight this guy! don't insul...     0\n",
            "\n",
            "[3257 rows x 2 columns], 'val_data':                                                  tweet label\n",
            "0    @user @user oh, hidden revenge and anger...i r...     0\n",
            "1    if not then #teamchristine bc all tana has don...     0\n",
            "2    hey @user #fields in #skibbereen give your onl...     0\n",
            "3    why have #emmerdale had to rob #robron of havi...     0\n",
            "4    @user i would like to hear a podcast of you go...     0\n",
            "..                                                 ...   ...\n",
            "369  @user @user if #trump #whitehouse aren't held ...     0\n",
            "370  @user which #chutiya #producer #invested in #c...     0\n",
            "371  russia story will infuriate trump today. media...     0\n",
            "372                        shit getting me irritated 😠     0\n",
            "373  @user @user if this didn't make me so angry, i...     0\n",
            "\n",
            "[374 rows x 2 columns], 'batch_size': 24, 'filter_sizes': [3, 4, 5], 'num_filters': [100, 100, 100], 'dropout': 0.5, 'lr': 0.001, 'train': True}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch.optim as optim\n",
        "from ray import train\n",
        "\n",
        "config = {\"train_data\":df_train,\"val_data\":df_val,\n",
        "          \"batch_size\":tune.grid_search([8,16,24]),\n",
        "          \"filter_sizes\":[3,4,5],\n",
        "          \"num_filters\":tune.grid_search([[100,100,100],[150,150,150]]),\n",
        "          \"dropout\":tune.choice([0.5,0.6,0.8]),\n",
        "          \"lr\": tune.grid_search([0.1, 0.001, 0.01]),\n",
        "          \"train\": True\n",
        "          }\n",
        "\n",
        "reporter = CLIReporter(\n",
        "        metric_columns=[\"accuracy\", \"loss\", \"f1_score\"])\n",
        "\n",
        "##### getting the best hyperparameters for label 0 and 1 model ######\n",
        "analysis = tune.run(model_emotions().train_model,\n",
        "                    config=config,\n",
        "                    verbose=3,\n",
        "                    resources_per_trial = {'gpu': 1, 'cpu': 2 },\n",
        "                    progress_reporter = reporter,\n",
        "                    resume = 'AUTO',\n",
        "                    )\n",
        "\n",
        "print(\"Best config: \", analysis.get_best_config(\"f1_score\", \"max\"))\n",
        "\n",
        "# Get a dataframe for analyzing trial results.\n",
        "df1 = analysis.dataframe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uihD2bfq6HhC",
        "outputId": "c1a27efd-287e-4220-f881-ad151051ec96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The test accuracy of the model is 0.5847994089126587\n",
            "The f1-score of the model is 0.5379133224487305\n"
          ]
        }
      ],
      "source": [
        "# model with the best parameters for dataset 1\n",
        "word2idx,max_len,label_01_model = model_emotions().train_model(config = {\"train_data\":df_train,\"val_data\":df_val,\n",
        "                                                                        \"batch_size\": 24,\n",
        "                                                                        \"filter_sizes\":[3,4,5],\n",
        "                                                                        \"num_filters\":[100,100,100],\n",
        "                                                                        \"dropout\":0.5,\n",
        "                                                                        \"lr\": 0.001,\n",
        "                                                                         \"train\":False})\n",
        "\n",
        "# test the data\n",
        "test_data_processed,test_labels = model_emotions().get_processed_data(df_test, word2idx, max_len)\n",
        "test_data_processed = test_data_processed.to(device)\n",
        "test_labels = test_labels.to(device)\n",
        "test_label_predicted = label_01_model(test_data_processed)\n",
        "\n",
        "# Accuracy of model on test_data\n",
        "accuracy = torch.mean((torch.argmax(test_label_predicted, dim=1) == test_labels).float())\n",
        "print(\"The test accuracy of the model is {}\".format(accuracy))\n",
        "\n",
        "# F1-Macro on test_data\n",
        "\n",
        "f1_score_model = multiclass_f1_score(test_label_predicted, test_labels, average=\"macro\",num_classes=4).to(device)\n",
        "print(\"The f1-score of the model is {}\".format(f1_score_model))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pFe8eMttNEDe"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}